{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(ticker):\n",
    "\n",
    "    filename = '../data/' + ticker + '_1min_firstratedata.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    df['ticker'] = ticker\n",
    "\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    df[\"date\"] = df[\"timestamp\"].dt.date\n",
    "    df[\"time\"] = df[\"timestamp\"].dt.time\n",
    "    return df\n",
    "\n",
    "ticker = 'SPY'\n",
    "df = load_data(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def daily_summary(ticker):\n",
    "\n",
    "    # Data Preprocessing\n",
    "    filename = \"../data/\" + ticker + \"_1min_firstratedata.csv\"\n",
    "    df = pd.read_csv(filename)\n",
    "    df[\"ticker\"] = ticker\n",
    "\n",
    "    # time handling\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    df[\"Date\"] = df[\"timestamp\"].dt.date\n",
    "    df[\"time\"] = df[\"timestamp\"].dt.time\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Crop to market hours\n",
    "    df = df[(df[\"time\"] >= datetime.time(9, 30)) & (df[\"time\"] <= datetime.time(16, 0))]\n",
    "\n",
    "    # Get the earliest and latest times for each day\n",
    "    # Find the indices of the earliest and latest rows for each day\n",
    "    earliest_indices = df.groupby(\"Date\")[\"time\"].idxmin()\n",
    "    latest_indices = df.groupby(\"Date\")[\"time\"].idxmax()\n",
    "\n",
    "    # Concatenate the indices and drop duplicates\n",
    "    indices_to_keep = pd.concat([earliest_indices, latest_indices]).drop_duplicates()\n",
    "\n",
    "    # Create a new DataFrame with only the selected rows\n",
    "    df = df.loc[indices_to_keep]\n",
    "    df = df.sort_values(by=[\"Date\"])\n",
    "    df.drop([\"timestamp\", \"high\", \"low\"], axis=1, inplace=True)\n",
    "\n",
    "    df = df.groupby([\"Date\", \"time\"]).filter(lambda group: len(group) != 2)\n",
    "    \n",
    "    open_rows = df[df[\"time\"] == datetime.time(9, 30)][[\"Date\", \"open\", \"time\"]]\n",
    "    close_rows = df[df[\"time\"] == datetime.time(16, 0)][[\"Date\", \"close\", \"time\"]]\n",
    "\n",
    "    merged_df = pd.merge(open_rows, close_rows, on=[\"Date\"])\n",
    "    merged_df[\"dif\"] = merged_df[\"close\"] - merged_df[\"open\"]\n",
    "    merged_df[\"dif\"] = merged_df[\"dif\"].round(2)\n",
    "\n",
    "    merged_df[\"percent_change\"] = (merged_df[\"dif\"] / merged_df[\"open\"]).round(4)\n",
    "    merged_df[\"percent_change\"] = merged_df[\"percent_change\"] * 100\n",
    "\n",
    "    merged_df[\"up\"] = merged_df[\"dif\"] > 0\n",
    "    merged_df[\"up\"] = merged_df[\"up\"].astype(int)\n",
    "\n",
    "    merged_df.to_csv(\"../temp/merged.csv\", index=False)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the RSI indicator with period n to a df\n",
    "\n",
    "def RSI(df, n):\n",
    "    \"function to calculate RSI\"\n",
    "    delta = df[\"close\"].diff()\n",
    "    delta = delta[1:]\n",
    "    up, down = delta.copy(), delta.copy()\n",
    "    up[up < 0] = 0\n",
    "    down[down > 0] = 0\n",
    "    df[\"up\"] = up.round(4)\n",
    "    df[\"down\"] = down.round(4)\n",
    "    AVG_Gain = df[\"up\"].rolling(window=n).mean()\n",
    "    AVG_Loss = abs(df[\"down\"].rolling(window=n).mean())\n",
    "    RS = AVG_Gain / AVG_Loss\n",
    "    RSI = 100.0 - (100.0 / (1.0 + RS))\n",
    "    df[\"RSI_14\"] = RSI.round(4)\n",
    "    df = df.drop(columns=[\"up\", \"down\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "df = RSI(df, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def simulate_trade_RSI(date, entry, exit_high, exit_low, max_trades, df):\n",
    "    df_day = df[(df[\"date\"] == date) & (df[\"time\"] >= datetime.time(9, 30, 0)) & (df[\"time\"] <= datetime.time(16, 0, 0))]\n",
    "    trade_log = pd.DataFrame(columns=[\"Date\", \"Direction\", \"Entry\", \"Exit\", \"TimeEnter\", \"TimeExit\", \"Gain%\", \"Gain$\", \"ExitCondition\"])\n",
    "\n",
    "    trades, in_trade = 0, False\n",
    "\n",
    "    for i in range(1, len(df_day)):\n",
    "        entry_rsi = (df_day[\"RSI_14\"].iloc[i - 1] < entry and df_day[\"RSI_14\"].iloc[i] >= entry)\n",
    "\n",
    "        exit_profit = (df_day[\"RSI_14\"].iloc[i - 1] >= exit_high and df_day[\"RSI_14\"].iloc[i] < exit_high)\n",
    "        exit_stoploss = (df_day[\"RSI_14\"].iloc[i - 1] <= exit_low and df_day[\"RSI_14\"].iloc[i] > exit_low)\n",
    "        exit_endofday = (df_day[\"time\"].iloc[i] == datetime.time(16, 0, 0))\n",
    "        exit_condition = \"MaxProfit\" if exit_profit else \"StopLoss\" if exit_stoploss else \"EndOfDay\" if exit_endofday else None\n",
    "\n",
    "        if not in_trade and entry_rsi:\n",
    "            entry_price, in_trade, time_enter = df_day[\"close\"].iloc[i], True, df_day[\"time\"].iloc[i - 1]\n",
    "\n",
    "        elif in_trade and (exit_profit or exit_stoploss or exit_endofday):\n",
    "            exit_price = df_day[\"close\"].iloc[i]\n",
    "            trade_gain_percent = round(((exit_price - entry_price) / entry_price) * 100, 2)\n",
    "            trade_gain_net = round(exit_price - entry_price, 2)\n",
    "\n",
    "            trade_log.loc[len(trade_log)] = pd.Series({\n",
    "                \"Date\": date,\n",
    "                \"Direction\": \"Long\",\n",
    "                \"Entry\": entry,\n",
    "                \"High\": exit_high,\n",
    "                \"Low\": exit_low,\n",
    "                \"Entry\": entry_price,\n",
    "                \"Exit\": exit_price,\n",
    "                \"TimeEnter\": time_enter,\n",
    "                \"TimeExit\": df_day[\"time\"].iloc[i],\n",
    "                \"Gain%\": trade_gain_percent,\n",
    "                \"Gain$\": trade_gain_net,\n",
    "                \"ExitCondition\": exit_condition\n",
    "            })\n",
    "\n",
    "            trades, entry_price, in_trade = trades + 1, 0, False\n",
    "\n",
    "            # Check if the maximum number of trades is reached\n",
    "            if trades >= max_trades:\n",
    "                break\n",
    "\n",
    "    return trade_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the simulated trades for a range of dates into a single dataframe\n",
    "\n",
    "def simulate_date_range(start_date, end_date, entry, exit_high, exit_low, max_trades, df):\n",
    "    day_datas = []\n",
    "\n",
    "    for n in range((end_date - start_date).days + 1):\n",
    "        date = start_date + datetime.timedelta(n)\n",
    "        day_data = simulate_trade_RSI(date, entry, exit_high, exit_low, max_trades, df)\n",
    "        if day_data is not None:\n",
    "            day_datas.append(day_data)\n",
    "\n",
    "    day_datas = pd.concat(day_datas, ignore_index=True)\n",
    "\n",
    "    return day_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = simulate_date_range(datetime.date(2022, 9, 30), datetime.date(2023, 9, 30), 50, 70, 30, 1, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart the results of the simulated trades\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# line chart of running gain%\n",
    "def chart_gain_percent(trades):\n",
    "    trades[\"RunningGain%\"] = trades[\"Gain%\"].cumsum()\n",
    "    fig = px.line(trades, y=\"RunningGain%\", title=\"Running Gain%\")\n",
    "    fig.show()\n",
    "\n",
    "chart_gain_percent(trades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart a scatter of the sum of the gain% for each day against \n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "underlying = daily_summary(ticker)\n",
    "print(underlying.columns)\n",
    "print(trades.columns)\n",
    "\n",
    "combined = pd.merge(trades, underlying, on=[\"Date\"])\n",
    "\n",
    "#print(combined.columns)\n",
    "#combined.head()\n",
    "\n",
    "fig = px.scatter(combined, x=\"percent_change\", y=\"Gain%\", title=\"Gain% vs Underlying Gain%\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades\n",
    "# histogram of the trade gain%\n",
    "\n",
    "\n",
    "fig = px.histogram(trades, x=\"Gain%\", nbins=100, title=\"Histogram of Trade Gain%\")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Gain%\",\n",
    "    yaxis_title=\"Count\",\n",
    "    bargap=0.1\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Trades:\", len(trades))\n",
    "print(\"Total Gain%:\", round(trades[\"Gain%\"].sum(), 2))\n",
    "print(\"Average Gain%:\", round(trades[\"Gain%\"].mean(), 5))\n",
    "print(\"Median Gain%:\", round(trades[\"Gain%\"].median(), 2))\n",
    "\n",
    "print(\"Average Gain$:\", round(trades[\"Gain$\"].mean(), 5))\n",
    "print(\"Median Gain$:\", round(trades[\"Gain$\"].median(), 2))\n",
    "\n",
    "\n",
    "trades[\"Gain%\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades.to_csv('../temp/trades.csv', index=False)\n",
    "\n",
    "trades[\"ExitCondition\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(trades, x=\"TimeEnter\", nbins=50, title=\"Histogram of Time to Enter Trade\")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Count\",\n",
    "    bargap=0.1\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of entry time vs gain%\n",
    "\n",
    "fig = px.scatter(trades, x=\"TimeEnter\", y=\"Gain%\", title=\"Entry Time vs Gain%\")\n",
    "fig.update_layout(xaxis_title=\"Time\",yaxis_title=\"Gain%\",bargap=0.1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi_ranged_backtest_single_pnl(df, rsi_enter, rsi_exit, maxTrades, ticker):\n",
    "    res = pd.DataFrame()\n",
    "    res.loc[0, 'Ticker'] = ticker\n",
    "    res.loc[0, 'StartDate'] = df['Date'].min()\n",
    "    res.loc[0, 'EndDate'] = df['Date'].max()\n",
    "    res.loc[0, 'Entry'] = rsi_enter\n",
    "    res.loc[0, 'Exit'] = rsi_exit,\n",
    "    res.loc[0, 'MaxTrades'] = maxTrades,\n",
    "    res.loc[0, 'TotalTrades'] = len(df)\n",
    "    res.loc[0, 'TotalPercentGain'] = round(df['Gain%'].sum(), 2)\n",
    "    res.loc[0, 'AveragePercentGain'] = round(df['Gain%'].mean(), 2)\n",
    "    res.loc[0, 'MaxPercentGain'] = round(df['Gain%'].max(), 2)\n",
    "    res.loc[0, 'MinPercentGain'] = round(df['Gain%'].min(), 2)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_rsi_backtest(tickers, max_trades, indicator_pairs):\n",
    "    results = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"Ticker\",\"StartDate\",\"EndDate\",\"Entry\",\"Exit\",\"TotalTrades\",\n",
    "            \"TotalPercentGain\",\"AveragePercentGain\",\"MaxPercentGain\",\"MinPercentGain\"])\n",
    "\n",
    "    for e in indicator_pairs:\n",
    "        for f in max_trades:\n",
    "            for g in tickers:\n",
    "\n",
    "                df = load_data(g)\n",
    "                df = RSI(df, 14)\n",
    "\n",
    "                print(\"testing TICKER/ENTER/EXIT/MAXTRADES:\", g, e[0], e[1], f)\n",
    "                trades = simulate_date_range(datetime.date(2022, 9, 30), datetime.date(2023, 9, 30), e[0], e[1], f, df)\n",
    "                pnl = rsi_ranged_backtest_single_pnl(trades, e[0], e[1], f, g)\n",
    "                results.loc[len(results)] = pnl.loc[0]\n",
    "\n",
    "    results = results.sort_values(by=[\"TotalPercentGain\"], ascending=False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_rsi_backtest_transaction_tensors(tickers, max_trades, indicator_triplets):\n",
    "    \n",
    "    results = pd.DataFrame(columns=[\"Date\", \"Direction\", \"Entry\", \"Exit\", \"TimeEnter\", \"TimeExit\", \"Gain%\", \"Gain$\", \"ExitCondition\"])\n",
    "\n",
    "    for e in indicator_triplets:\n",
    "        for f in max_trades:\n",
    "            for g in tickers:\n",
    "\n",
    "                df = load_data(g)\n",
    "                df = RSI(df, 14)\n",
    "\n",
    "                print(g, e[0], e[1], e[2], f)\n",
    "                trades = simulate_date_range(datetime.date(2022, 9, 30), datetime.date(2023, 9, 30), e[0], e[1], e[2], f, df)\n",
    "                fileanme = '../temp/rsi_backtests/' + g + '_' + str(e[0]) + '_' + str(e[1]) + '_' + str(e[2]) + '_' + str(f) + '.csv'\n",
    "                trades.to_csv(fileanme, index=False)\n",
    "                results = pd.concat([results, trades], ignore_index=True)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['SPY', 'TSLA']\n",
    "max_trades = [1, 2]\n",
    "entries = [(50, 60, 40), (60, 70, 50)]\n",
    "\n",
    "results = multi_rsi_backtest_transaction_tensors(tickers, max_trades, entries)\n",
    "results.to_csv('../temp/mega_RSI_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['AAPL', 'AMZN', 'META', 'MSFT', 'TSLA', 'SPY', 'EEM', 'VXX', 'QQQ']\n",
    "max_trade_options = [1, 2, 3, 4]\n",
    "\n",
    "# Throwing shit at the wall to test my new training rig\n",
    "\n",
    "symetrics = [(50, 60, 40), (50, 70, 30), (60, 80, 40), (40, 60, 20)]\n",
    "long_leaning = [(50, 80, 40), (60, 80, 40), (35, 65, 20)]\n",
    "early_exits = [(50, 70, 40), (50, 80, 40)]\n",
    "momentum = [(70, 80, 60), (70, 90, 50), (80, 90, 70)]\n",
    "scalps = [(50, 55, 45), (70, 75, 65), (70, 80, 65)]\n",
    "\n",
    "all_entries = symetrics + long_leaning + early_exits + momentum + scalps\n",
    "\n",
    "# each of these take about 7 seconds to run \n",
    "# so in total, this should be 36*13 trials, 468 experiments, comes to just under an hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = multi_rsi_backtest_transaction_tensors(tickers, max_trades, all_entries)\n",
    "results.to_csv('../temp/mega_RSI_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
